{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097490bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecce586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD dataset\n",
    "cfd_df = pd.read_csv(\"apollo_cfd_database.csv\")\n",
    "\n",
    "# RENAME columns with corresponding names\n",
    "new_col_names = {\n",
    "    \"X\":\"x\",\n",
    "    \"Y\":\"y\",\n",
    "    \"Z\":\"z\",\n",
    "    \"pw (Pa)\":\"pressure\",\n",
    "    \"qw (W/m^2)\":\"heat_flux\",\n",
    "    \"Me\": \"edge_mach_number\",\n",
    "    \"delta (m)\": \"boundary_layer_thickness\",\n",
    "    \"theta (m)\": \"momentum_thickness\",\n",
    "    \"Re-theta\": \"momentum_thickness_reynolds_number\",\n",
    "    \"tauw (Pa)\": \"shear_stress\",\n",
    "    \"mach (-)\": \"mach\",\n",
    "    \"velocity (m/s)\":\"velocity\",\n",
    "    \"density (kg/m^3)\": \"density\",\n",
    "    \"aoa (degrees)\": \"angle_of_attack\",\n",
    "    \"dynamic_pressure (Pa)\":\"dynamic_pressure\"\n",
    "    }\n",
    "cfd_df.rename(columns=new_col_names, inplace=True)\n",
    "cfd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bf62d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE independent and dependent variables\n",
    "ind_var = [\"mach\", \"dynamic_pressure\", \"angle_of_attack\"]\n",
    "dep_var = \"pressure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bb20e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTER independent and dependent from entire dataframe\n",
    "filtered_df = cfd_df[ind_var + [dep_var]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a5d566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUP by independent variables IMPORTANT!!!: There should be 185 rows\n",
    "grouped = (\n",
    "    filtered_df.groupby(ind_var)[dep_var]\n",
    "      .apply(lambda x: x.values)\n",
    "      .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44120609",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8640161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE Pytorch dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class CFDSolutions(torch.utils.data.Dataset):\n",
    "    def __init__(self, grouped_df):\n",
    "        self.X = grouped_df[ind_var].values.astype('float32')\n",
    "        self.Y = np.stack(grouped_df[dep_var].values).astype('float32')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.X[idx]), torch.from_numpy(self.Y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb6f410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZE dataset with Grouped data\n",
    "dataset = CFDSolutions(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a42565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST dataset, tensor X = [number of dependent variables], tensor Y = [50176 independent variables]\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8d8498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE model arquitecture\n",
    "class ShieldModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ShieldModel, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(in_features = len(ind_var), out_features = 64)\n",
    "        self.linear2 = torch.nn.Linear(in_features = 64, out_features = 128)\n",
    "        self.linear3 = torch.nn.Linear(in_features = 128, out_features = 256)\n",
    "        self.linear4 = torch.nn.Linear(in_features = 256, out_features = 50176)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.linear4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acafa3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST model\n",
    "dummy_batch = torch.zeros(10, len(ind_var))\n",
    "my_model = ShieldModel()\n",
    "predictions = my_model(dummy_batch)\n",
    "print(dummy_batch.shape, predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2520cdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE training loop\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "def train_model(n_epochs, threshold, model, loss_fn, optimizer, scheduler, train_loader, val_loader, device):\n",
    "    # for gpu training\n",
    "    model = model.to(device)\n",
    "    loss_fn = loss_fn.to(device)\n",
    "    # for plotting\n",
    "    liveloss = PlotLosses()\n",
    "    for epoch in range(n_epochs):\n",
    "        logs = {}\n",
    "        # initialize control variables.\n",
    "        correct = 0\n",
    "        cumulative_loss = 0\n",
    "        n_samples = 0\n",
    "        # Set the model in training mode.\n",
    "        model.train()\n",
    "        for idx_batch, (X, y) in enumerate(train_loader):\n",
    "            model.zero_grad()\n",
    "            # Move (x,y) data to GPU (if so desired).\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            # Compute predictions.\n",
    "            pred = model(X)\n",
    "            # Compute loss.\n",
    "            loss = loss_fn(pred, y)\n",
    "            cumulative_loss += loss.item()\n",
    "            # Count how many correct in batch.\n",
    "            pred_placeholder = pred.detach()\n",
    "            percent_diff_each = (pred_placeholder - y).abs() / y.abs() * 100\n",
    "            mean_percent_diff = percent_diff_each.mean(dim=1)\n",
    "            mask = mean_percent_diff < threshold\n",
    "            correct += mask.sum().cpu().item()\n",
    "            n_samples += mask.size(0)\n",
    "            # Compute gradients (autograd).\n",
    "            loss.backward()\n",
    "            # Run one basic training step of SGD.\n",
    "            optimizer.step()\n",
    "            # Keep track of loss and accuracy for the plot.\n",
    "            n_batches = 1 + idx_batch\n",
    "            logs['loss'] = cumulative_loss / n_batches\n",
    "            logs['accuracy'] = correct / n_samples\n",
    "        # initialize control variables.\n",
    "        correct = 0\n",
    "        cumulative_loss = 0\n",
    "        n_samples = 0\n",
    "        # Set the model in evaluation mode.\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for idx_batch, (X, y) in enumerate(val_loader):\n",
    "                # Move data to GPU if needed.\n",
    "                X = X.to(device)\n",
    "                y = y.to(device)\n",
    "                # Compute predictions.\n",
    "                pred = model(X)\n",
    "                # Compute loss.\n",
    "                loss = loss_fn(pred, y)\n",
    "                cumulative_loss += loss.item()\n",
    "                # Count how many correct in batch.\n",
    "                pred_placeholder = pred.detach()\n",
    "                percent_diff_each = (pred_placeholder - y).abs() / y.abs() * 100\n",
    "                mean_percent_diff = percent_diff_each.mean(dim=1)\n",
    "                mask = mean_percent_diff < threshold\n",
    "                correct += mask.sum().cpu().item()\n",
    "                n_samples += mask.size(0)\n",
    "                # Keep track of loss and accuracy for the plot.\n",
    "                n_batches = 1 + idx_batch\n",
    "                logs['val_loss'] = cumulative_loss / n_batches\n",
    "                logs['val_accuracy'] = correct / n_samples\n",
    "        # Update the plot with new logging information.\n",
    "        liveloss.update(logs)\n",
    "        liveloss.send()\n",
    "\n",
    "        if scheduler != -1:\n",
    "            scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26442683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE training parameters\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(grouped, test_size=0.30, random_state=42)\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 16\n",
    "lr = 0.0001\n",
    "threshold = 10\n",
    "\n",
    "train_set = CFDSolutions(train_df)\n",
    "val_set = CFDSolutions(val_df)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size, shuffle=False)\n",
    "\n",
    "model = ShieldModel()\n",
    "loss_fn = torch.nn.SmoothL1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr)\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "train_model(n_epochs, threshold, model, loss_fn, optimizer, -1, train_loader, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a824da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMPLE 1 of 185 point for testing\n",
    "idx_sample = 180\n",
    "x_sample = grouped.loc[idx_sample, ind_var].to_numpy(dtype='float32')\n",
    "y_sample = grouped.loc[idx_sample, dep_var]\n",
    "x_sample_tensor = torch.tensor([x_sample], dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb232496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST 1 sample with model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = model(x_sample_tensor).squeeze(0).cpu().numpy()\n",
    "print(prediction)\n",
    "print(y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01006a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATE mean difference for 1 sample and its prediction\n",
    "percent_diff_each = np.abs(prediction - y_sample) / np.abs(y_sample) * 100\n",
    "mean_percent_diff = percent_diff_each.mean()\n",
    "mean_percent_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e517141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLLECT coordiantes for ploting\n",
    "xyz_df = cfd_df[[\"x\", \"y\", \"z\"]].iloc[0:50176]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99879421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATTACH correct and prediction\n",
    "xyz_df[\"correct\"] = y_sample\n",
    "xyz_df[\"prediction\"] = prediction\n",
    "xyz_df[\"percent_difference\"] = np.abs(prediction - y_sample) / np.abs(y_sample) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad219ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4258f7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT correct points\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    xyz_df,\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    z=\"z\",\n",
    "    color=\"correct\",\n",
    "    color_continuous_scale=\"Viridis\" ,\n",
    "    hover_data=xyz_df.columns\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b870e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT predicted points\n",
    "fig = px.scatter_3d(\n",
    "    xyz_df,\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    z=\"z\",\n",
    "    color=\"prediction\",\n",
    "    color_continuous_scale=\"Viridis\" ,\n",
    "    hover_data=xyz_df.columns\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef37b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT diffrence points\n",
    "fig = px.scatter_3d(\n",
    "    xyz_df,\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    z=\"z\",\n",
    "    color=\"percent_difference\",\n",
    "    color_continuous_scale=\"Viridis\" ,\n",
    "    hover_data=xyz_df.columns\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
